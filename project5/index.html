<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Project 5</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            max-width: 1000px;
            margin: 20px auto;
            text-align: left;
        }
        h1 {
            color: #530f0f;
            text-align: center;
            
        }
        h2 {
            color: #8e1600;
            text-align: center;
            margin-top: 20px;
        }
        h3 {
            color: #804141;
            margin: 20px 10px 10px 10px;
            text-align: center;
        }
        h4 {
            color: #664848;
            margin: 20px 10px 10px 10px;
        }
        h5 {
            color: #a26b6b;
            margin: 20px 10px 10px 10px;
        }
        p {
            margin: 20px 10px 10px 10px;
        }
        
        img {
            max-width: 600px;
            height: auto;
            margin: 20px 10px 10px 10px;

        }

        figure {
            text-align: center; /* centers both image and caption */
            margin: 20px 0;
        }
        figcaption {
            font-family: 'Open Sans', sans-serif;
            font-size: 14px;
            color: #555;
            margin-top: 5px;
        }
        .image-row {
            
            display: flex;         
            gap: 20px;             
            flex-wrap: wrap;       
            justify-content: center; 
        }
        .image-row figure {
            margin: 0;
            text-align: center;
            flex: 0 1 200px;       
        }
        .image-row img {
            width: 200px;
            height: auto;
            display: block;
            image-rendering: pixelated;
        }
        .image-column {
            display: flex;
            flex-direction: column; 
            gap: 20px;      
            align-items: center;
        }

        .image-column figure {
            margin: 0;
            text-align: center;
        }

        .image-column img {
            max-width: 90%;  
            height: auto;
            display: block;
        }
        figure.side-by-side {
            display: flex;
            align-items: center;
            gap: 15px;
        }
        

    </style>
</head>




<body>



<!-- 
<h1>Project 5A: The Power of Diffusion Models</h1>
<h2>Part 0: Set Up</h2>
            <h3> Prompt Embeddings </h3>
            <figure class="side-by-side">  <img src="p5pt0/pembs.png" style="height:400px;" > <figcaption>After gaining access to the DeepFloyd IF diffusion model through Hugging Face, I generated prompt embeddings using the provided Hugging Face clusters. Here are some of the prompts I embedded. </figcaption> </figure>

            <h3> Model Outputs: <code>num_inference_steps = 20</code> </h3>
                <p>  Random seed used: <code> seed_everything(100) </code> </p>
                <div class="image-row"> <figure> <img src = "p5pt0/seed100/download.png">  <figcaption> Prompt: a sunflower wearing sunglasses </figcaption> </figure>
                                        <figure> <img src = "p5pt0/seed100/download-1.png">  <figcaption> Prompt: a beach with an umbrella </figcaption> </figure>
                                        <figure> <img src = "p5pt0/seed100/download-2.png">  <figcaption> Prompt: a volleyball team playing basketball </figcaption> </figure>  </div>

            <h3> Model Outputs: <code>num_inference_steps = 60</code> </h3>
                <p>  Random seed used: <code> seed_everything(100) </code> </p>
                <div class="image-row"> <figure> <img src = "p5pt0/seed100/stepsize 60/download.png">  <figcaption> Prompt: a sunflower wearing sunglasses </figcaption> </figure>
                                        <figure> <img src = "p5pt0/seed100/stepsize 60/download-1.png">  <figcaption> Prompt: a beach with an umbrella </figcaption> </figure>
                                       <figure> <img src = "p5pt0/seed100/stepsize 60/download-2.png">  <figcaption> Prompt: a volleyball team playing basketball </figcaption> </figure>  </div>

            <h3> Reflection </h3>
                <p> The "a sunflower wearing glasses" prompt at low <code> num_inference_steps </code> doesn't capture the image well. It often fails to generate the sunglasses, but is able to capture the sunfloweriness of the sunflower just fine. At higher <code>num_inference_steps</code>, however, it is able to do create the sunflower wearing sunglasses, and at a higher quality. </p>
                <p> The "a beach with an umbrella" prompt seems to do well with both higher and lower <code> num_inference_steps </code>. In both images, we are able to make out the beach through the presence of sand and water at the horizon, and a umbrella. Interestingly, both images resemble digitally drawn backdrops. Both are relatively high quality, and retrieve what the prompt is trying to achieve. </p>
                <p> The "a volleyball team playing basketball" prompt does worse than the other two, but is still passable as a realistic image if not observed closely. With a lower <code> num_inference_steps </code>, we see that the humans are more unnaturally placed, and there is no basketball to be seen, but there is an absense of a volleyball net and the girls don't really seem like they're playing volleyball, but are wearing volleyball uniforms. But with a higher <code> num_inference_steps </code>, we see a very low net, a basketball, and girls in volleyball attire/poses, but they don't seem to be playing basketball. Both images seem natural and seem to conform to the given prompt at a glance, but don't correspond to the prompt the same way the other prompts do. </p>


<h2>Part 1: Sampling Loops</h2>
    <h3>1.1 Implementing the Forward Process</h3>
            <h4> Goal: Implement <code> noisy_im = forward(im, t) </code> </h4>
                <p> This <code>forward</code> function implements a one forward diffusion step in a diffusion model, as it's useful in simulating progressively adding noise to a clean image over time. It takes a clean image tensor <code>im</code> of shape <code>(1, 3, 64, 64)</code> and a timestep <code>t</code>, then returns a noisy version of the clean image at that timestep. </p>
                <figure> <img src = "p5 pt1/pt1.1/formula.png" > </figure>
                <p> First, we sample <code>epsilon</code> from Gaussian N(0,1) noise (same shape as the image). Then, we get cumulative products of diffusion alphas at timestep <code>t</code>, <code>alpha_bar_t</code>, to determine how much of the original image should by incorporated. The clean image is scaled by <code>sqrt(alpha_bar_t)</code> and the noise is scaled by <code>sqrt(1 - alpha_bar_t)</code>, and their sum produces a noisy image <code>im_noisy</code>. </p>
            <h4> Implementation </h4> <figure> <img src = "p5 pt1/pt1.1/imp.png" > </figure>

            <h4> Campanile at Noise Levels <code>t = 250, 500, 750 </code> </h4>
                        <div class="image-row"> <figure> <img src = "p5 pt1/pt1.4/original.png">  <figcaption> Original (scaled) Berkeley Campanile </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/pt1.1/camp250.png">  <figcaption> Noisy Campanile at t=250 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/pt1.1/camp500.png">  <figcaption> Noisy Campanile at t=500 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/pt1.1/camp750.png">  <figcaption> Noisy Campanile at t=750 </figcaption> </figure>  </div>


    
    <h3>1.2 Classical Denoising</h3>
            <h4> Goal: Gaussian blur filtering to try to remove the noise using <code>torchvision.transforms.functional.gaussian_blur</code> with <code>kkernel_size = [7, 7]</code> and <code> sigma = 1</code>. </h4>
                        <div class="image-row"> <figure> <img src = "p5 pt1/pt1.1/camp250.png">  <figcaption> Noisy Campanile at t=250 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/pt1.1/camp500.png">  <figcaption> Noisy Campanile at t=500 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/pt1.1/camp750.png">  <figcaption> Noisy Campanile at t=750 </figcaption> </figure>  </div>
                        <div class="image-row"> <figure> <img src = "p5 pt1/1.2/kernelsize5/download.png">  <figcaption> Gaussian Blur Denoising at t=250 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/1.2/kernelsize7/download-1.png">  <figcaption> Gaussian Blur Denoising at t=500 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/1.2/kernelsize7/download-2.png">  <figcaption> Gaussian Blur Denoising at t=750 </figcaption> </figure>  </div>

    <h3>1.3 One-Step Denoising</h3>
            <p> Here, we aim to denoise using our model. First, we run the forward process on the image at the given timestep <code>t</code>, and then predict the noise using the pretrained denoiser. Now, we can generate the clean estimate by solving for <code>x_0</code> from the equation in Part 1.1. </p>
            <h4> Goal: Denoise Using the Denoiser in one step. </h4>
                        <div class="image-row"> <figure> <img src = "p5 pt1/pt1.1/camp250.png">  <figcaption> Noisy Campanile at t=250 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/pt1.1/camp500.png">  <figcaption> Noisy Campanile at t=500 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/pt1.1/camp750.png">  <figcaption> Noisy Campanile at t=750 </figcaption> </figure>  </div>
                        <div class="image-row"> <figure> <img src = "p5 pt1/1.3/y250/download-1.png">  <figcaption> Model Noise Estimate at t=250 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/1.3/y500/download-1.png">  <figcaption> Model Noise Estimate at t=500 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/1.3/y750/download-1.png">  <figcaption> Model Noise Estimate at t=750 </figcaption> </figure>  </div>     
                        <div class="image-row"> <figure> <img src = "p5 pt1/1.3/y250/download copy.png">    <figcaption> One-Step Denoised Campanile at t=250 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/1.3/y500/download-2.png">  <figcaption> One-Step Denoised Campanile at t=500 </figcaption> </figure>
                                                <figure> <img src = "p5 pt1/1.3/y750/download-2.png">  <figcaption> One-Step Denoised Campanile at t=750 </figcaption> </figure>  </div>                        

    <h3>1.4 Iterative Denoising </h3>
            <p> Instead of taking one step towards the clean estimate, we can take multiple steps toward the clean estimate of the given noisy image in iterative denoising. </p>
            <p> Essentially, we are trying to implement this function: </p>
            <h4>Create <code>strided_timesteps</code>: a list of monotonically decreasing timesteps, starting at 990, with a stride of 30, eventually reaching 0. </h4>                 <figure> <img src = "p5 pt1/pt1.4/strides.png" > </figure>
            <h4> Also initialize the timesteps using <code></code>stage_1.scheduler.set_timesteps(timesteps=strided_timesteps)</code> </h4>
            <h4>Complete the <code>iterative_denoise</code> function:</h4>         <p> Essentially, we are trying to implement this equation: </p>    <figure class="side-by-side">  <img src="p5 pt1/pt1.4/formula.png" style="height:100;" > <figcaption> • <code>x_t</code> is your image at timestep <code>t</code> <br> 
                                                                                                                                                                                             • <code>x_t'</code> (<code>t < t'</code>) is your noisy image at timestep <code>t'</code> (a less noisy image) <br>
                                                                                                                                                                                             • <code>alpha_bar_t</code> helps determine how much of the clean image we want to retain at time <code>t</code>
                                                                                                                                                                                             • <code>alpha_t</code> =  <code>alpha_bar_t</code> / <code>alpha_bar_t'</code> <br>
                                                                                                                                                                                             • <code>beta_t</code> =  <code>1 - alpha_t</code> <br>
                                                                                                                                                                                             • <code> x_0 </code> is our current estimate of the clean image <br>
                                                                                                                                                                                             • <code> v_sigma </code> is random noise predicted by DeepFloyd. </figcaption> </figure>
            <h4> Implementation </h4>                 <figure> <img src = "p5 pt1/pt1.4/imp.png" > </figure>


            <h4> Show the noisy Campanile every 5th loop of denoising (gradually becomes less noisy). </h4>
                            <div class="image-row">         <figure> <img src = "p5 pt1/pt1.4/t690.png">    <figcaption> Iterative Denoising, Noisy Campanile at t = 690 </figcaption> </figure>
                                                            <figure> <img src = "p5 pt1/pt1.4/t540.png">    <figcaption> Iterative Denoising, Noisy Campanile at t = 540 </figcaption> </figure>
                                                            <figure> <img src = "p5 pt1/pt1.4/t390.png">    <figcaption> Iterative Denoising, Noisy Campanile at t = 390 </figcaption> </figure>
                                                            <figure> <img src = "p5 pt1/pt1.4/t240.png">    <figcaption> Iterative Denoising, Noisy Campanile at t = 240 </figcaption> </figure>
                                                            <figure> <img src = "p5 pt1/pt1.4/t90.png">    <figcaption> Iterative Denoising, Noisy Campanile at t = 90 </figcaption> </figure> </div>
            
            <h4> Cross-Denoising-Method Comparisons </h4>
                            <div class="image-row">         <figure> <img src = "p5 pt1/pt1.4/original.png">    <figcaption> Original (scaled) Campanile </figcaption> </figure>
                                                            <figure> <img src = "p5 pt1/pt1.4/iterativedenoising.png">    <figcaption> Iterative Denoising: final clean image prediction  </figcaption> </figure>
                                                            <figure> <img src = "p5 pt1/pt1.4/onestep.png">    <figcaption> One Step Denoising: predicted clean image using a single denoising step (looks worse than iterative denoising)</figcaption> </figure>
                                                            <figure> <img src = "p5 pt1/pt1.4/guassianblur.png">    <figcaption> Gaussian-Filter Denoising: predicted clean image using gaussian blurring </figcaption> </figure>  </div>




    <h3>1.5 Diffusion Model Sampling </h3> <p> By using the <code> iterative_denoise </code> function and starting at <code>im_noise</code> = a random noisy image of desired shape, <code> i_start = 0</code>, <code> prompt_embeds = prompt_embeds_dict["a high quality photo"]</code>, and <code>timesteps=strided_timesteps</code>, we can generate images from scratch. </p>
                                <h4> Sampled Images: </h4>
                                <div class="image-row">     <figure> <img src = "p5 pt1/pt 1.5/download-5.png">    </figure>
                                                            <figure> <img src = "p5 pt1/pt 1.5/download.png">     </figure>
                                                            <figure> <img src = "p5 pt1/pt 1.5/download-6.png">     </figure>
                                                            <figure> <img src = "p5 pt1/pt 1.5/download-9.png">   </figure> 
                                                            <figure> <img src = "p5 pt1/pt 1.5/download-13.png">   </figure> </div>


    <h3>1.6 Classifier-Free Guidance (CFG)</h3>  <p> The images sampled in 1.5 aren't always the best. But using CFG, we can improve image quality by combining conditional and unconditional noise estimates in the diffusion process. The strength of guidance is controlled by scale, which determines <code> epsilon = uncond_epsilon + scale * (cond_epsilon - uncond_epsilon) </code>.</p>
            <h4> Goal: Implement <code>iterative_denoise_cfg</code>  </h4>  <figure> <img src = "p5 pt1/1.6/imp.png" > </figure>
                <p> We can then generate better-quality pictures using  <code>iterative_denoise_cfg</code>  with <code>im_noise</code> = a random noisy image of desired shape,<code> i_start = 0</code>, <code> prompt_embeds = prompt_embeds_dict["a high quality photo"]</code>, <code>uncond_prompt_embeds = prompt_embeds_dict['']</code>, <code>timesteps=strided_timesteps</code>, and <code>scale = 7</code>.</p>

            <h4> Images using <code>iterative_denoise_cfg</code> with <code> scale = 7 </code> = CFG scale = gamma. </h4>
                                    <div class="image-row">     <figure> <img src = "p5 pt1/1.6/download-2.png">    </figure> 
                                                                <figure> <img src = "p5 pt1/1.6/download-5.png">    </figure> 
                                                                <figure> <img src = "p5 pt1/1.6/download copy.png">    </figure> 
                                                                <figure> <img src = "p5 pt1/1.6/download-10.png">    </figure> 
                                                                <figure> <img src = "p5 pt1/1.6/download-3 copy.png">    </figure> </div>


    <h3> 1.7 Image-to-image Translation </h3>
            <h4> SD Edit: Campanile </h4>
                                    <div class="image-row">     <figure> <img src = "p5 pt1/p5 pt1.7/1.7/campanile/istart1.png">  <figcaption> SDEdit with <code>i_start = 1</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/campanile/istart3.png"> <figcaption> SDEdit with <code>i_start = 3</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/campanile/istart5.png">  <figcaption> SDEdit with <code>i_start = 5</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/campanile/istart7.png">  <figcaption> SDEdit with <code>i_start = 7</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/campanile/istart10.png"> <figcaption> SDEdit with <code>i_start = 10</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/campanile/istart20.png">   <figcaption> SDEdit with <code>i_start = 20</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/campanile/campanile.png"> <figcaption>  Original Campanile </figcaption>  </figure>  </div>

            <h4> SD Edit: Mountains </h4>
                                    <div class="image-row">     <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own3/istart1.png">  <figcaption> SDEdit with <code>i_start = 1</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own3/istart3.png"> <figcaption> SDEdit with <code>i_start = 3</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own3/istart5.png">  <figcaption> SDEdit with <code>i_start = 5</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own3/istart7.png">  <figcaption> SDEdit with <code>i_start = 7</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own3/istart10.png"> <figcaption> SDEdit with <code>i_start = 10</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own3/istart20.png">   <figcaption> SDEdit with <code>i_start = 20</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own3/download.png"> <figcaption>  Original  </figcaption>  </figure>  </div>

                        
            <h4> SD Edit: Man </h4>
                                    <div class="image-row">     <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own2/1.png">  <figcaption> SDEdit with <code>i_start = 1</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own2/2.png"> <figcaption> SDEdit with <code>i_start = 3</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own2/3.png">  <figcaption> SDEdit with <code>i_start = 5</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own2/4.png">  <figcaption> SDEdit with <code>i_start = 7</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own2/5.png"> <figcaption> SDEdit with <code>i_start = 10</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own2/6.png">   <figcaption> SDEdit with <code>i_start = 20</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7/own2/download.png"> <figcaption>  Original  </figcaption>  </figure>  </div>
<h3> 1.7.1 Editing Hand-Drawn and Web Images </h3>
         <h4> One Image from the Web </h4>
                                        <div class="image-row"> <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/web/1.png">  <figcaption> Flower with <code>i_start = 1</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/web/3.png"> <figcaption> Flower with <code>i_start = 3</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/web/5.png">  <figcaption> Flower with <code>i_start = 5</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/web/7.png">  <figcaption> Flower with <code>i_start = 7</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/web/10.png"> <figcaption> Flower with <code>i_start = 10</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/web/20.png">   <figcaption> Flower with <code>i_start = 20</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/web/download.png"> <figcaption>  Original  </figcaption>  </figure>  </div>

        <h4> First hand-drawn image </h4>
                                        <div class="image-row"> <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw1/1.png">  <figcaption> Room with <code>i_start = 1</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw1/2.png"> <figcaption> Room with <code>i_start = 3</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw1/3.png">  <figcaption> Room with <code>i_start = 5</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw1/4.png">  <figcaption> Room with <code>i_start = 7</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw1/5.png"> <figcaption> Room with <code>i_start = 10</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw1/6.png">   <figcaption> Room with <code>i_start = 20</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw1/download.png"> <figcaption>  Original  </figcaption>  </figure>  </div>

         <h4> Second hand-drawn image </h4>
                                        <div class="image-row"> <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw2/download-1.png">  <figcaption> Sunflower with <code>i_start = 1</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw2/download-2.png"> <figcaption> Sunflower with <code>i_start = 3</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw2/download-3.png">  <figcaption> Sunflower with <code>i_start = 5</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw2/download-4.png">  <figcaption> Sunflower with <code>i_start = 7</code></figcaption>   </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw2/download-5.png"> <figcaption> Sunflower with <code>i_start = 10</code></figcaption>    </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw2/download-6.png">   <figcaption> Sunflower with <code>i_start = 20</code></figcaption>  </figure> 
                                                                <figure> <img src = "p5 pt1/p5 pt1.7/1.7.1/draw2/download.png"> <figcaption>  Original  </figcaption>  </figure>  </div>

<h3> 1.7.2 Inpainting </h3>
        <p>    To implement Inpainting functionality, we need a diffusion model and a binary mask to allow us to edit an image by replacing content outside of masked regions of the image while keeping the image contents inside the mask intact. To do this, at each diffusion denoising loop, we want to update our image according to: </p> <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/formula.png" > </figure>
        <p> This ensures that the pixels outside the mask retain the original image content (with appropriate noise), while pixels inside the mask are replaced with new content generated by the model.</p>
        <h4> Implement <code>impaint</code></h4>
            <p> Code follows the same structure as <code>iterative_denoise_cfg</code>, but instead of <code>image = pred_prev_image</code>, I use:</p><figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/imp.png" > </figure>

        <h4> The Campanile Impainted 1</h4> <div class="image-row"> <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/camp/c.png">         <figcaption>  Campanile      </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/camp/m.png">         <figcaption>  Mask           </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/camp/q.png">         <figcaption>  Pixels to Change  </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/camp/download.png">  <figcaption>  Campanile Inpainted  </figcaption>  </figure>  </div>


        <h4> The Campanile Impainted 2</h4> <div class="image-row"> <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/camp2/c.png">         <figcaption>  Campanile      </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/camp2/m.png">         <figcaption>  Mask           </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/camp2/q.png">         <figcaption>  Pixels to Change </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/camp2/download.png">  <figcaption>  Campanile Inpainted  </figcaption>  </figure>  </div>

        <h4> The Sunset Road Impainted</h4> <div class="image-row"> <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/own1/c.png">       <figcaption>  Sunset Road      </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/own1/m.png">         <figcaption>  Mask           </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/own1/q.png">         <figcaption>  Pixels to Change  </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/own1/download-6.png">  <figcaption>  Sunset Road Inpainted  </figcaption>  </figure>  </div>


        <h4> The Sunflower Bouquet Impainted</h4> <div class="image-row"> <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/own2/c.png">       <figcaption>   Sunflower Bouquet    </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/own2/m.png">         <figcaption>  Mask           </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/own2/q.png">         <figcaption>  Pixels to Change  </figcaption>    </figure> 
                                                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.2/own2/download.png">  <figcaption>   Sunflower Bouquet Inpainted  </figcaption>  </figure>  </div>


<h3> 1.7.3 Text-Conditional Image-to-image Translation </h3> <p> Using the <code>prompt_embeds</code> parameter of <code>iterative_denoise_cfg </code>, we can guide the projection even more, but this time with text.</p>
            <h4> Edits of the Campanile: <code> prompt_embeds = prompt_embeds_dict["a rocket ship"]</code></h4><div class="image-row"> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/camp/download.png">  <figcaption> Rocket Ship at Noise Level 1           </figcaption>  </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/camp/download-1.png">  <figcaption>  Rocket Ship at Noise Level 3 </figcaption>  </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/camp/download-2.png"> <figcaption>   Rocket Ship at Noise Level 5                                   </figcaption>    </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/camp/download-3.png">  <figcaption>    Rocket Ship at Noise Level 7                                      </figcaption>   </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/camp/download-4.png">  <figcaption>    Rocket Ship at Noise Level 10                                          </figcaption>   </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/camp/download-5.png"> <figcaption>      Rocket Ship at Noise Level 20                                             </figcaption>    </figure> 
                                    <figure> <img src = "p5 pt1/pt1.4/original.png"> <figcaption>  Original Campanile  </figcaption>  </figure>  </div>

            <h4> Edits of the Sunset Road: <code> prompt_embeds = prompt_embeds_dict["a beach with an umbrella"]</code></h4><div class="image-row"> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own1/download.png">  <figcaption>  Noise Level 1           </figcaption>  </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own1/download-1.png">  <figcaption>  Noise Level 3 </figcaption>  </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own1/download-2.png"> <figcaption>   Noise Level 5                                   </figcaption>    </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own1/download-3.png">  <figcaption>    Noise Level 7                                      </figcaption>   </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own1/download-4.png">  <figcaption>  Noise Level 10                                          </figcaption>   </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own1/download-5.png"> <figcaption>      Noise Level 20                                             </figcaption>    </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own1/download copy.png"> <figcaption>  Original Sunset Road  </figcaption>  </figure>  </div>

            <h4> Edits of the Sunflower Bouquet: <code> prompt_embeds = prompt_embeds_dict["a bouquet of marigold flowers"]</code></h4><div class="image-row"> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own2/noise1.png">  <figcaption>  Noise Level 1           </figcaption>  </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own2/noise3.png">  <figcaption>  Noise Level 3 </figcaption>  </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own2/noise5.png"> <figcaption>   Noise Level 5                                   </figcaption>    </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own2/noise7.png">  <figcaption>    Noise Level 7                                      </figcaption>   </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own2/noise10.png">  <figcaption>  Noise Level 10                                          </figcaption>   </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own2/noise20.png"> <figcaption>      Noise Level 20                                             </figcaption>    </figure> 
                                    <figure> <img src = "p5 pt1/p5 pt1.7/1.7.3/own2/download.png"> <figcaption>  Original Sunflower Bouquet  </figcaption>  </figure>  </div>


<h3> 1.8 Visual Anagrams </h3>
<p> Visual Anagrams are optical illusions where an image reveals different scenes depending on its orientation. </p>

    <h4>Method</h4>
                <ol>
                    <li> First, denoise an image <code>x</code> at timestep <code>t</code> with prompt <code>prompt1</code> to get noise estimate <code>epsilon1</code>.</li>
                    <li> Then, flip <code>x</code> (if we want 180 degree illusions) and denoise with <code>prompt2</code> to get noise estimate <code>epsilon2</code>.</li>
                    <li> Next, flip the image back and average the two noise estimates:</li> <pre><code>epsilon = (epsilon1 + flip(epsilon2)) / 2</code></pre>
                    <li> Lastly, denoise using <code>epsilon</code> to update the image, as done before.</li>
                </ol>
    <h4> Implement <code> make_flip_illusion </code> </h4> <p> This is how I changed the main body of <code>make_flip_illusion</code> . </p> <figure> <img src = "p5 pt1/pt1.8/imp.png" > </figure>   
    <h4> "a beach" and "a tulip field" </h4>       <div class="image-row"> <figure> <img src = "p5 pt1/pt1.8/beachtulip/1.png">  <figcaption> Beach </figcaption>  </figure> 
                                                                           <figure> <img src = "p5 pt1/pt1.8/beachtulip/2.png"> <figcaption> Tulip Field (Flipped) </figcaption>    </figure> </div>
    <h4> "a happy family" and "a bouquet" </h4>       <div class="image-row"> <figure> <img src = "p5 pt1/pt1.8/fambouqet/1.png">  <figcaption> Happy Family </figcaption>  </figure> 
                                                                           <figure> <img src = "p5 pt1/pt1.8/fambouqet/2.png"> <figcaption> Bouquet (Flipped) </figcaption>    </figure> </div>
    <h4>  "an oil painting of an old man" and "an oil painting of people around a campfire" </h4>       <div class="image-row"> <figure> <img src = "p5 pt1/pt1.8/manfire/1.png">  <figcaption>  "an oil painting of an old man" </figcaption>  </figure> 
                                                                           <figure> <img src = "p5 pt1/pt1.8/manfire/2.png"> <figcaption> "an oil painting of people around a campfire" (Flipped) </figcaption>    </figure> </div>
    <h4>  "a puppy" and "a raven" </h4>       <div class="image-row"> <figure> <img src = "p5 pt1/pt1.8/1.png">  <figcaption>  "a puppy" </figcaption>  </figure> 
                                                                           <figure> <img src="p5 pt1/pt1.8/2.png" style="transform: rotate(180deg); "> <figcaption> "a raven" (Flipped) </figcaption>    </figure> </div>
    


<h3> 1.9 Hybrid Images </h3> <p> We can also create hybrid images by combining features from two different prompts: Low-frequency details come from one prompt, and high-frequency details come from the other. </p>

  <h4>Method</h4>
    <ol>
        <li>First, generate two noise estimates <code>epsilon1</code> and <code>epsilon2</code> using the two text prompts <code>prompt1</code> and <code>prompt2</code> with the UNet diffusion model.</li>
        <li> Then, extract low frequencies from one noise estimate using a low-pass filter (<code>torchvision.transforms.functional.gaussian_blur</code>), and high frequencies from the other using a high-pass filter (<code>img - torchvision.transforms.functional.gaussian_blur</code>).</li>
        <li> Use Gaussian blur with kernel size 33 and sigma 2. </li>
        <li>Next, combine them to form the final noise estimate:</li> <pre><code>epsilon = low_pass(epsilon1) + high_pass(epsilon2)</code></pre>
        <li>Lastly, , denoise using <code>epsilon</code> to update the image, as done before.</li>
    </ol>

    <h4> Implement <code> make_hybrids </code> </h4> <p> This is how I changed the main body of <code>make_hybrids</code> . </p> <figure> <img src = "p5 pt1/1.9/imp.png" > </figure>    

    <h4> Cat (close) and Puppy (far) </h4> <div class="image-row">  <figure> <img src = "p5 pt1/1.9/catpuppy/1.png" >  <figcaption> Cat</figcaption> </figure> 
                                                                     <figure> <img src = "p5 pt1/1.9/catpuppy/1.png" style="width: 30%;">  <figcaption> Puppy</figcaption> </figure> 
                                                                     </div>

    <h4> Sunset (close) and Old Man (far) </h4> <div class="image-row"> <figure> <img src = "p5 pt1/1.9/man sunset/1.png" > <figcaption> Sunset</figcaption></figure> 
    <figure> <img src = "p5 pt1/1.9/man sunset/1.png" style="width: 30%;">  <figcaption>Old Man</figcaption> </figure> 
    </div>
    
    <h4> Witch (close) and Tree (far) </h4> <div class="image-row"> <figure> <img src = "p5 pt1/1.9/witchtree/1.png" >  <figcaption> Witch</figcaption></figure> 
<figure> <img src = "p5 pt1/1.9/witchtree/1.png" style="width: 30%;">   <figcaption> Tree</figcaption> </figure> 
  </div>


    <h4> Waterfalls (close) and Skull (far) </h4> <div class="image-row"> <figure> <img src = "p5 pt1/1.9/skull/1.png" > <figcaption> Waterfalls</figcaption></figure> 
    <figure> <img src = "p5 pt1/1.9/skull/1.png" style="width: 30%;">  <figcaption> Skull</figcaption> </figure> 
   </div>

 -->




<h1>Project 5B: Flow Matching from Scratch</h1>
    <h2>Part 1: Training a Single-Step Denoising UNet</h2> <h3> Goal: Denoise noisy image in one step, optimizing over L2 Loss</h3>
    
    <h2>1.1 Implementing the UNet </h2>
        <p> I implemented a simpler version of the UNet architecture used in diffusion models. The UNet consists of an upsampling and downsampling structure with skip connections, allowing both local and global features to be captured. The model takes in a noisy image as input and attempts to denoise the image.</p>
        <figure> <img src = "part B pt1/une.png" > </figure>

    <h2> 1.2 Using the UNet to Train a Denoiser  </h2> <p> To train the denoiser, I need to generate noisy z and clean x image pairs. To create the noisy image from the clean, I need to add noise proportional to sigma to the clean image. I sampled from the MNIST dataset, obtained Gaussian noise <code>epsilon</code> using <code>torch.randn_like</code>, and create a noisy z = x + epsilon * sigma .  I made sure to clamp the resulting values between 0 and 1 for better visualization.</p>  <h3>Visualizing the noising process: </h3> <figure> <img src = "part B pt1/pt1.2.png" > </figure>
    
    <h2> 1.1.2.1 Training </h2>
            <h3> Goal: Train a denoiser to denoisy noisy image <code>z</code> in one step, using L2 loss with <code> σ = 0.5 </code> applied to a clean image <code>x</code>. </h3>  <p> I trained the UNet model over a total of 5 epochs, using the AdamW optimizer to minimze L2 loss (MSE).</p> <p> Hyperparameters: </p> <ul> <li>batch_size = 256</li> <li>learning_rate = 1e-4</li> <li>noise_level = 0.5</li> <li>hidden_dim = 128</li> <li>num_epochs = 5</li> </ul>
            <h3> Training Loss Curve </h3> <figure> <img src = "part B pt1/savedmodels/training_curve.png" >  <figcaption>Training Loss Curve: Low loss achieved </figcaption></figure> 
            <h3> Sample results on the test set with noise level <code> σ = 0.5 </code> after the first and the fifth epoch </h3>
            <h3> On Random Images</h3>
                <div class="image-row">     <figure> <img src = "part B pt1/savedmodels/denoised_results_epoch_1.png" style="width:400px;">  <figcaption> Epoch 1 </figcaption>  </figure> 
                                            <figure> <img src = "part B pt1/savedmodels/denoised_results_epoch_5.png" style="width:400px;">  <figcaption> Epoch 5 </figcaption>  </figure> </div>
            
            <h4> To better compare the same test images' results at each saved epoch of the model: </h4>
                <div class="image-row">     <figure> <img src = "part B pt1/savedmodels/denoised_results_epoch_comparable_1.png" style="width:400px;">  <figcaption> Epoch 1 </figcaption>  </figure> 
                                            <figure> <img src = "part B pt1/savedmodels/denoised_results_epoch_comparable_5.png" style="width:400px;">  <figcaption> Epoch 5 </figcaption>  </figure> </div>
    <h2> 1.2.2 Out-of-Distribution Testing </h2>
            <p> The denoiser I just trained was trained on images noised at noise level <code> σ = 0.5 </code>, and it doesn't generalize well when test images are noised at different noise levels (called 'out of distribution' test images). </p>
            <h3> Sampled results on the test set with out-of-distribution noise levels: </h3>
            <h4> Small noise levels: <code> σ = [0.0, 0.2] </code> </h4>
                    <div class = "image-row">   <figure> <img src = "part B pt1/OODTesting/ood_sigma_0.0.png" style="width:300px;">  <figcaption> Noise Level 0.0 </figcaption>  </figure> 
                                              <figure> <img src = "part B pt1/OODTesting/ood_sigma_0.2.png" style="width:300px;">  <figcaption> Noise Level 0.2 </figcaption>  </figure> </div>

            <h4> Noise levels similar around <code>σ = 0.5 </code>:  <code> σ = [0.4, 0.5, 0.6] </code>  </h4>
                    <div class = "image-row">   <figure> <img src = "part B pt1/OODTesting/ood_sigma_0.4.png" style="width:300px;">  <figcaption> Noise Level 0.4 </figcaption>  </figure> 
                                              <figure> <img src = "part B pt1/OODTesting/ood_sigma_0.5.png" style="width:300px;">  <figcaption> Noise Level 0.5 </figcaption>  </figure> 
                                              <figure> <img src = "part B pt1/OODTesting/ood_sigma_0.6.png" style="width:300px;">  <figcaption> Noise Level 0.6 </figcaption>  </figure></div>
  
            <h4> High noise levels:  <code> σ = [0.8, 1.0] </code>  </h4>
                    <div class="image-row">   <figure> <img src = "part B pt1/OODTesting/ood_sigma_0.8.png" style="width:300px;">  <figcaption> Noise Level 0.8 </figcaption>  </figure> 
                                              <figure> <img src = "part B pt1/OODTesting/ood_sigma_1.0.png" style="width:300px;">  <figcaption> Noise Level 1.0 </figcaption>  </figure> </div>
            <p> The model clearly does not generalize well to high out of distribution noise levels, as it's not trained to learn them. </p>
  
    <h2> 1.2.3 Denoising Pure Noise </h2>   <p> In generation tasks, we feed models noise and expect them to generate meaningful outputs. I trained the UNet model on pure, random Guassian noise <code> z</code> implemented using <code> torch.rand_liken()</code>. I hope for the model to be able to denoise this noise to get clean image <code>x</code>. </p> <h3> Goal: Train a denoiser to denoise pure noise image <code>z</code> in one step, using L2 loss. </h3>  <p> I trained the UNet model over a total of 5 epochs, using the AdamW optimizer to minimze L2 loss (MSE).</p> <p> Hyperparameters: </p> <ul> <li>batch_size = 256</li> <li>learning_rate = 1e-4</li> <li>hidden_dim = 128</li> <li>num_epochs = 5</li> </ul>
            <h3> Training Loss Curve </h3> <figure> <img src = "part B pt1/purenoise/training_curve.png" >  <figcaption>Training Loss Curve: Doesn't converge. </figcaption></figure> 
            <h3> Sample results on pure noise after the first and the fifth epoch. </h3>   
                        <div class="image-row">   <figure> <img src = "part B pt1/purenoise/denoised_results_epoch_comparable_1.png" style="width:300px;">  <figcaption> After 1 epoch </figcaption>  </figure> 
                                                    <figure> <img src = "part B pt1/purenoise/denoised_results_epoch_comparable_5.png" style="width:300px;">  <figcaption> After 5 epochs </figcaption>  </figure> </div>
                                                    <p> As a note: Though the test image is displayed, it wasn't actually used to generate the noisy input to the model, only as a reference.     </p>
                                        
            <h3> Patterns observed, Possible Explanations </h3>
            <p> The generated outputs of the model is a consistent blend of all nine digits, clearly not resembling any one digit but not changing with different noise inputs. The model is attempting to average of all of the images it saw during training, as an attempt to minimize the L2 loss it used in training. 
                This is common when training models with MSE loss with very noisy/volatile data, where the model attempts to overlook the task at hand and instead minimzes L2 loss with an average guess. The model would end up doing this if it found no good patterns in the data, as the sum of squared distances to all training examples is minimized by predicting the mean of all examples in that case. 
                Our model is trained on pure noise, and isn't given a direction to help learn anything on the noise. So, on our model, the average best-guess output looks, naturally, like the blurry digit-accumulation generated above. </p>
                <p> And since on the training curve we saw that there's little decrease in loss from Epoch 1 to Epoch 5, we don't expect the model to improve much between these two epochs and is why there's similar output results between the two. </p>










</body>




</html>

